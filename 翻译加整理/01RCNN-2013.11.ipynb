{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rich feature hierarchies for accurate object detection and semantic segmentation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "利用丰富的层次特征准确实现目标检测和语义分割\n",
    "\n",
    "hierarchies 层次、\n",
    "Learning Multi-Level Hierarchies 分层强化学习\n",
    "semantic segmentation 语义分割 \n",
    "语义分割 在图像领域，语义指的是图像的内容，对图片意思的理解，输入一个人骑着自行车，能够将人和自行车分割开"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "在过去几年 ，目标检测在规范数据集PASCAL VOC上的测量性能逐渐趋于稳定\n",
    "\n",
    "canonical 规范的\n",
    "plateaued 趋于稳定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "表现最佳的方法是复杂的集合系统，通常将多个低级图像特征与高级上下文相结合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012—achieving a mAP of 53.3%."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "在本文中，我们提出了一种简单可扩展的目标检测算法，相比于之前在VOC2012上的最佳结果，平均精度提高了0.3，平均精度达到了53.3%。\n",
    "\n",
    "scalable 可扩展的\n",
    "mean average precision 平均精度\n",
    "voc 2012 是一个数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our approach combines two key insights (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "我们的方法结合了两个观点：一是：在候选区域上自下而上使用大型卷积神经网络。二是，当带标签的训练数据不足时，先针对辅助任务进行有监督预训练，再进行特定任务的调优，就可以产生明显的性能提升。\n",
    "\n",
    "scarce 稀缺\n",
    "high-capacity 大容量\n",
    "region proposals 候选区域\n",
    "候选区域方法：\n",
    "1.滑窗法(Sliding Window)：输入图像->不同大小窗口+滑动间隔->分类器打分确定分数高的->非极大值抑制（过滤重复的）\n",
    "2.选择性搜索(Selective Search):elective Search 的前期工作就是利用Graph-Based Image Segmentation的分割算法\n",
    "有监督学习：有特征有标签，经过训练得到特征和标签之间的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "因此我们将cnn与候选区域结合，这种方法叫做R-CNN：Regions with CNN features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www.cs.berkeley.edu/rbg/rcnn"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "我们列出了一些实验结果，可以深入了解网络学习，揭示图像丰富特征层次结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features matter. The last decade of progress on various visual recognition tasks has been based considerably on the use of SIFT [26] and HOG [7]. But if we look at performance on the canonical visual recognition task, PASCAL VOC object detection [12], it is generally acknowledged that progress has been slow during 2010-2012, with small gains obtained by building ensemble systems and employing minor variants of successful methods"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "特征很重要。在过去几十年间，各种计算机视觉识别任务都是建立在SITFT和HOG的基础之上。但是我们关注一下PASCAL VOC这个经典的视觉识别任务，2010-2012年进展缓慢，取得的微小进步都是通过构建一些集成系统和采用一些成功方法的变种才达到的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIFT and HOG are blockwise orientation histograms, a representation we could associate roughly with complex cells in V1, the first cortical area in the primate visual path-way. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "SIFT和HOG是块方向直方图(blockwise orientation histograms)，一种类似大脑初级皮层V1层复杂细胞的表示方法."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But we also know that recognition occurs several stages downstream, which suggests that there might be hierarchical, multi-stage processes for computing features that are even more informative for visual recognition."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "但我们知道识别发生在多个下游阶段，也就是说对于视觉识别来说，更有价值的信息，是层次化的，多个阶段的特征。\n",
    "\n",
    "hierarchical: 分层的\n",
    "multi-stage：多阶段的\n",
    "informative ：有价值的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fukushima’s “neocognitron” [16], a biologically-inspired hierarchical and shift-invariant model for pattern recognition, was an early attempt at just such a process."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fukushima的“neocognitron，一种受生物学启发用于模式识别的层次化、移动不变性模型，算是这方面最早的尝试。\n",
    "\n",
    "shift-invariant 平移不变性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The neocognitron, however, lacked a supervised training al- gorithm. LeCun et al. [23] provided the missing algorithm by showing that stochastic gradient descent, via backprop-agation, can train convolutional neural networks (CNNs), a class of models that extend the neocognitron."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "然而neocognitron缺乏监督学习算法。Lecun等人的工作表明基于反向传播的随机梯度下降(SGD)对训练卷积神经网络（CNNs）非常有效，CNNs被认为是继承自neocognitron的一类模型。\n",
    "\n",
    "supervised 监督\n",
    "neocognitron 神经认知机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs saw heavy use in the 1990s (e.g., [24]), but then fell out of fashion, particularly in computer vision, with the rise of support vector machines. In 2012, Krizhevsky et al. [22] rekindled interest in CNNs by showing substantially higher image classification accuracy on the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) [9, 10]. Their success resulted from training a large CNN on 1.2 million labeled images, together with a few twists on LeCun’s CNN (e.g., max(x,0) rectifying non-linearities and “dropout” regularization)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cnn十九世纪九十年代被广泛使用，但是随着支持向量机的兴起他随之过时。2012年，Krizhevsky等人通过在基于网络的大规模图像挑战大赛中的图像分类的优异表现重新引起人们对cnns的兴趣。他们的成功在于在120万的标签图像上使用了一个大型的CNN，并且对LeCUN的CNN进行了一些改造（比如ReLU和Dropout Regularization）。\n",
    "\n",
    "\n",
    "支持向量机\n",
    "relu（激活函数）\n",
    "Dropout 丢弃正则化"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
